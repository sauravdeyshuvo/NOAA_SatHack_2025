{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fd027a5-24cc-43c5-a32f-9a3f1febbf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 58 counties → D:\\1Research\\2025\\NOAA_SatHack\\figures\\CA_county_DSI_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from netCDF4 import Dataset\n",
    "from datetime import datetime, timedelta\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# 0. DIRECTORIES and PARAMETERS\n",
    "glm_dir   = r'D:\\1Research\\2025\\NOAA_SatHack\\data\\glm_ca_subset'\n",
    "dry_tif   = r'D:\\1Research\\2025\\NOAA_SatHack\\data\\sentinel_ca\\sentinel_flammability_0p1deg.tif'\n",
    "\n",
    "# shapefile folder and path for CA counties\n",
    "shp_dir   = r'D:\\1Research\\2025\\NOAA_SatHack\\cb_2018_us_county_500k'\n",
    "shp_path  = os.path.join(shp_dir, 'cb_2018_us_county_500k.shp')\n",
    "\n",
    "# output Excel\n",
    "out_xlsx  = r'D:\\1Research\\2025\\NOAA_SatHack\\figures\\CA_county_DSI_summary.xlsx'\n",
    "\n",
    "# geographic bounds and resolution \n",
    "lon_min, lon_max = -124.5, -114.0\n",
    "lat_min, lat_max =   32.0,    42.0\n",
    "res = 0.1\n",
    "\n",
    "# 1. LOAD THE DRYNESS RASTER\n",
    "with rasterio.open(dry_tif) as src:\n",
    "    dryness = src.read(1)\n",
    "nlat, nlon = dryness.shape\n",
    "\n",
    "# build cell‐center coordinates\n",
    "lon_edges = np.linspace(lon_min, lon_min + nlon * res, nlon + 1)\n",
    "lat_edges = np.linspace(lat_min, lat_min + nlat * res, nlat + 1)\n",
    "lon_centers = (lon_edges[:-1] + lon_edges[1:]) / 2\n",
    "lat_centers = (lat_edges[:-1] + lat_edges[1:]) / 2\n",
    "lons, lats = np.meshgrid(lon_centers, lat_centers)\n",
    "\n",
    "# 2. BUILD HOURLY FLASH COUNTS\n",
    "pattern = re.compile(r'_c(\\d{4})(\\d{3})(\\d{2})(\\d{2})(\\d{2})')\n",
    "counts_hour = {}\n",
    "\n",
    "for nc in glob.glob(os.path.join(glm_dir, '*.nc')):\n",
    "    fn = os.path.basename(nc)\n",
    "    m = pattern.search(fn)\n",
    "    if not m:\n",
    "        continue\n",
    "    year, doy, hr, mn, sc = map(int, m.groups())\n",
    "    dt = datetime(year, 1, 1) + timedelta(days=doy-1,\n",
    "                                         hours=hr,\n",
    "                                         minutes=mn,\n",
    "                                         seconds=sc)\n",
    "    hour_key = dt.strftime('%Y%m%d%H')\n",
    "\n",
    "    if hour_key not in counts_hour:\n",
    "        counts_hour[hour_key] = np.zeros((nlat, nlon), dtype=float)\n",
    "\n",
    "    with Dataset(nc, 'r') as ds:\n",
    "        lat = ds.variables['flash_lat'][:]\n",
    "        lon = ds.variables['flash_lon'][:]\n",
    "\n",
    "    mask = (\n",
    "        (lon >= lon_min)  & (lon < lon_max) &\n",
    "        (lat >= lat_min)  & (lat < lat_max)\n",
    "    )\n",
    "    lon_f = lon[mask]\n",
    "    lat_f = lat[mask]\n",
    "    if lon_f.size == 0:\n",
    "        continue\n",
    "\n",
    "    ix = np.digitize(lon_f, lon_edges) - 1\n",
    "    iy = np.digitize(lat_f, lat_edges) - 1\n",
    "\n",
    "    grid = counts_hour[hour_key]\n",
    "    for x, y in zip(ix, iy):\n",
    "        if 0 <= x < nlon and 0 <= y < nlat:\n",
    "            grid[y, x] += 1\n",
    "\n",
    "# 3. LOAD CA COUNTIES and PREPARE MASKS\n",
    "counties = gpd.read_file(shp_path)\n",
    "ca = counties[counties.STATEFP == '06'].copy()\n",
    "ca = ca.reset_index(drop=True)\n",
    "\n",
    "# for each county build a boolean mask of grid‐cells whose center lies within it\n",
    "county_masks = []\n",
    "for geom in ca.geometry:\n",
    "    pts = [Point(x, y) for x, y in zip(lons.ravel(), lats.ravel())]\n",
    "    contains = np.array([geom.contains(pt) for pt in pts])\n",
    "    county_masks.append(contains.reshape(nlat, nlon))\n",
    "\n",
    "# 4. EXTRACT and AVERAGE DSI PER COUNTY\n",
    "# list of hours \n",
    "hours = sorted(counts_hour.keys())\n",
    "n_hours = len(hours)\n",
    "\n",
    "# compute DSI time‐series per county\n",
    "county_dsi_means = np.zeros((len(ca), n_hours), dtype=float)\n",
    "\n",
    "for t_idx, hr in enumerate(hours):\n",
    "    flash_grid = counts_hour[hr]\n",
    "    dsi = flash_grid * dryness  # grid of DSI\n",
    "    for j, mask in enumerate(county_masks):\n",
    "        # mean over all cells in county \n",
    "        vals = dsi[mask]\n",
    "        county_dsi_means[j, t_idx] = vals.mean() if vals.size else 0.0\n",
    "\n",
    "# average over time\n",
    "county_dsi_avg = county_dsi_means.mean(axis=1)\n",
    "\n",
    "# assemble DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name of county': ca.NAME,  \n",
    "    'DSI values':     county_dsi_avg\n",
    "})\n",
    "\n",
    "# 5. SAVE TO EXCEL\n",
    "df.to_excel(out_xlsx, index=False)\n",
    "print(f\"Wrote {len(df)} counties → {out_xlsx}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
